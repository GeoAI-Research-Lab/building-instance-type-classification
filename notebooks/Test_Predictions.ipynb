{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/5ury4pr454th/building-scene-classification/blob/main/Test_Predictions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vz2u_wL0v9Nr",
        "outputId": "ad8f80d4-df32-4885-f70f-5a8fb249faef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: grpc://10.20.207.138:8470\n",
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.20.207.138:8470\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.20.207.138:8470\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "# for basic file navigation and driving mount\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# some basic libraries\n",
        "import xgboost\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# importing for basic image operations\n",
        "import cv2 as cv\n",
        "from PIL import Image\n",
        "from PIL import ImageOps\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "# data structures\n",
        "from collections import OrderedDict\n",
        "\n",
        "# importing pretrained models\n",
        "from tensorflow.keras.applications import efficientnet\n",
        "\n",
        "# for splitting data\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# prerequisites for training models\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import Sequential\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# for selecting better metrics\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# initialize TPU\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "    print('Device:', tpu.master())\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "except:\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHPmaNQS1eCW"
      },
      "outputs": [],
      "source": [
        "# variables to change\n",
        "\n",
        "TRAIN_IMG_DIR_PATH = \"/content/gdrive/Othercomputers/My Laptop/Dataset Images/instances/train/\"\n",
        "TEST_IMG_DIR_PATH = \"/content/gdrive/Othercomputers/My Laptop/Dataset Images/instances/test/\"\n",
        "TRAIN_SC_DIR_PATH = \"/content/gdrive/Othercomputers/My Laptop/Dataset Images/scenes/train_renamed/all_resized\"\n",
        "TEST_SC_DIR_PATH = \"/content/gdrive/Othercomputers/My Laptop/Dataset Images/scenes/test_renamed/all_resized\"\n",
        "model_path = \"/content/gdrive/MyDrive\"\n",
        "classes = [\"commercial\", \"residential\", \"industrial\", \"others\"]\n",
        "\n",
        "INPUT_IMG_WIDTH = 250\n",
        "INPUT_IMG_HEIGHT = 350\n",
        "VERTICAL = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VZvpE_H0RIa"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "with strategy.scope():\n",
        "  new_eff_model = tf.keras.models.load_model(model_path + '/' + 'model_weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZd52xTW4fk1"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "target_class = \"residential\"\n",
        "residential_prediction_mapping = OrderedDict()\n",
        "\n",
        "with strategy.scope():\n",
        " \n",
        "  for file_name in os.listdir(TEST_IMG_DIR_PATH + target_class):\n",
        "\n",
        "    img = Image.open(TEST_IMG_DIR_PATH + target_class + '/'+ file_name)\n",
        "    building_image = np.array(ImageOps.fit(img,(250, 350), Image.ANTIALIAS))\n",
        "    building_image = np.expand_dims(building_image, axis = 0)\n",
        "    residential_prediction_mapping[target_class + '/'+ file_name] = new_eff_model.predict(building_image)\n",
        "\n",
        "target_class = \"commercial\"\n",
        "commercial_prediction_mapping = OrderedDict()\n",
        "with strategy.scope():\n",
        "  \n",
        "  for file_name in os.listdir(TEST_IMG_DIR_PATH + target_class):\n",
        "    img = Image.open(TEST_IMG_DIR_PATH + target_class + '/'+ file_name)\n",
        "    building_image = np.array(ImageOps.fit(img,(250, 350), Image.ANTIALIAS))\n",
        "    building_image = np.expand_dims(building_image, axis = 0)\n",
        "    commercial_prediction_mapping[target_class + '/'+ file_name] = new_eff_model.predict(building_image)\n",
        "\n",
        "target_class = \"industrial\"\n",
        "industrial_prediction_mapping = OrderedDict()\n",
        "with strategy.scope():\n",
        "  \n",
        "  for file_name in os.listdir(TEST_IMG_DIR_PATH + target_class):\n",
        "    img = Image.open(TEST_IMG_DIR_PATH + target_class + '/'+ file_name)\n",
        "    building_image = np.array(ImageOps.fit(img,(250, 350), Image.ANTIALIAS))\n",
        "    building_image = np.expand_dims(building_image, axis = 0)\n",
        "    industrial_prediction_mapping[target_class + '/'+ file_name] = new_eff_model.predict(building_image)\n",
        "\n",
        "target_class = \"others\"\n",
        "others_prediction_mapping = OrderedDict()\n",
        "with strategy.scope():\n",
        "  \n",
        "  for file_name in os.listdir(TEST_IMG_DIR_PATH + target_class):\n",
        "  \n",
        "    img = Image.open(TEST_IMG_DIR_PATH + target_class + '/'+ file_name)\n",
        "    building_image = np.array(ImageOps.fit(img,(250, 350), Image.ANTIALIAS))\n",
        "    building_image = np.expand_dims(building_image, axis = 0)\n",
        "    others_prediction_mapping[file_name] = new_eff_model.predict(building_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnGB8jlN59nt"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "others_predictions = OrderedDict()\n",
        "\n",
        "for file_name in others_prediction_mapping.keys():\n",
        "  # others_predictions[file_name] = np.argmax(others_prediction_mapping[file_name], axis = 1)[0]\n",
        "  others_predictions[file_name] = others_prediction_mapping[file_name]\n",
        "\n",
        "others_scene_predictions = OrderedDict()\n",
        "for file_name in others_predictions.keys():\n",
        "  scene_file_name = '_'.join(os.path.splitext(file_name)[0].split('_')[-3:]) + os.path.splitext(file_name)[1]\n",
        "  if scene_file_name not in others_scene_predictions.keys():\n",
        "    others_scene_predictions[scene_file_name] = [others_predictions[file_name]]\n",
        "  else:\n",
        "    others_scene_predictions[scene_file_name].append(others_predictions[file_name])\n",
        "\n",
        "residential_predictions = OrderedDict()\n",
        "for file_name in residential_prediction_mapping.keys():\n",
        "  # residential_predictions[file_name] = np.argmax(residential_prediction_mapping[file_name], axis = 1)[0]\n",
        "  \n",
        "  residential_predictions[file_name] = residential_prediction_mapping[file_name]\n",
        "\n",
        "residential_scene_predictions = OrderedDict()\n",
        "for file_name in residential_predictions.keys():\n",
        "  scene_file_name = '_'.join(os.path.splitext(file_name)[0].split('_')[-3:]) + os.path.splitext(file_name)[1]\n",
        "  if scene_file_name not in residential_scene_predictions.keys():\n",
        "    residential_scene_predictions[scene_file_name] = [residential_predictions[file_name]]\n",
        "  else:\n",
        "    residential_scene_predictions[scene_file_name].append(residential_predictions[file_name])\n",
        "\n",
        "commercial_predictions = OrderedDict()\n",
        "for file_name in commercial_prediction_mapping.keys():\n",
        "  # commercial_predictions[file_name] = np.argmax(commercial_prediction_mapping[file_name], axis = 1)[0]\n",
        "\n",
        "  commercial_predictions[file_name] = commercial_prediction_mapping[file_name]\n",
        "commercial_scene_predictions = OrderedDict()\n",
        "for file_name in commercial_predictions.keys():\n",
        "  scene_file_name = '_'.join(os.path.splitext(file_name)[0].split('_')[-3:]) + os.path.splitext(file_name)[1]\n",
        "  if scene_file_name not in commercial_scene_predictions.keys():\n",
        "    commercial_scene_predictions[scene_file_name] = [commercial_predictions[file_name]]\n",
        "  else:\n",
        "    commercial_scene_predictions[scene_file_name].append(commercial_predictions[file_name])\n",
        "\n",
        "industrial_predictions = OrderedDict()\n",
        "for file_name in industrial_prediction_mapping.keys():\n",
        "  # industrial_predictions[file_name] = np.argmax(industrial_prediction_mapping[file_name], axis = 1)[0]\n",
        "\n",
        "  industrial_predictions[file_name] = industrial_prediction_mapping[file_name]\n",
        "industrial_scene_predictions = OrderedDict()\n",
        "for file_name in industrial_predictions.keys():\n",
        "  scene_file_name = '_'.join(os.path.splitext(file_name)[0].split('_')[-3:]) + os.path.splitext(file_name)[1]\n",
        "  if scene_file_name not in industrial_scene_predictions.keys():\n",
        "    industrial_scene_predictions[scene_file_name] = [industrial_predictions[file_name]]\n",
        "  else:\n",
        "    industrial_scene_predictions[scene_file_name].append(industrial_predictions[file_name])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "authorship_tag": "ABX9TyP+lmv1Hgd2zHS7wYiiZz3I",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Test Predictions.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
